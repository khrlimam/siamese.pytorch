{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import pathlib\n",
    "from torch.utils import data\n",
    "from siamese_dataset_example import SiamesePairDataset\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import pandas\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "from models.siamese_resnet import SiameseResnet\n",
    "import log_compiler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import random\n",
    "import PIL\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "from mediumdataset import SiameseNetworkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trfm_valid = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trfm_train = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "target_trfrm = transforms.Compose([\n",
    "    lambda x: [x],\n",
    "    torch.Tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters\n",
    "A few arbitrary predefined parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.003\n",
    "NUM_EPOCH = 10\n",
    "ARCHITECTURE = 'resnet101'\n",
    "PRINT_EVERY = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'dataset/train/facescrub'\n",
    "valid_path = 'dataset/valid/facescrub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Siamese Network Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Siamese Pair Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating similar pair from\t dataset/train/facescrub: 100%|██████████| 98/98 [00:01<00:00, 73.34it/s]\n",
      "generating different pair from\t dataset/train/facescrub: 100%|██████████| 7679514/7679514 [00:53<00:00, 143549.85it/s]\n",
      "generating similar pair from\t dataset/valid/facescrub: 100%|██████████| 98/98 [00:00<00:00, 409.30it/s]\n",
      "generating different pair from\t dataset/valid/facescrub: 100%|██████████| 1356375/1356375 [00:07<00:00, 170782.11it/s]\n"
     ]
    }
   ],
   "source": [
    "trainset = SiamesePairDataset(root=train_path, ext='', transform=trfm_train, target_transform=target_trfrm, glob_pattern='*/*.[jJpP]*')\n",
    "validset = SiamesePairDataset(root=valid_path, ext='', transform=trfm_valid, target_transform=target_trfrm, glob_pattern='*/*.[jJpP]*')\n",
    "trainloader = data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validloader = data.DataLoader(validset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfolder = ImageFolder('dataset/train/facescrub')\n",
    "trainset = SiameseNetworkDataset(trainfolder, transform=trfm_valid, target_transform=target_trfrm, should_invert=False)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "validfolder = ImageFolder('dataset/valid/facescrub')\n",
    "validset = SiameseNetworkDataset(validfolder, transform=trfm_valid, target_transform=target_trfrm, should_invert=False)\n",
    "validloader = DataLoader(validset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train loader: 29, number of valid loader (13), each has 256\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of train loader: {len(trainloader)}, number of valid loader ({len(validloader)}), each has {BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Loss\n",
    "This function used to calculate the loss/cost of our input image, based on this paper by Yan Lecun http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf. Because siamese is not classification problem rather a distance problem which means we need to compute the difference between two images hence we need another type of loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, device, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, output1, output2, Y):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        euclidean_distance = euclidean_distance.to(self.device)\n",
    "        loss_contrastive = torch.mean((1-Y) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (Y) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(val, threshold=0.5):\n",
    "    return val > threshold\n",
    "\n",
    "def log_training_result(numepoch, batchsize, lrate, accuracy, precision, f1, tp, tn, fp, fn, fc, model, name='training_logs.csv'):\n",
    "    with open(name, 'r') as f:\n",
    "        train_number = len(f.readlines())\n",
    "    detail = log_compiler.compile(numepoch, batchsize, lrate, accuracy, precision, f1, tp, tn, fp, fn, fc, train_number, model)\n",
    "    data = [batchsize,lrate,numepoch,round(accuracy, 2),round(f1, 2),round(precision, 2),tp,tn,fp,fn,f'logs/{train_number}.md']\n",
    "    log_compiler.write_log_file(train_number, detail)\n",
    "    with open(name, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "    print(\"data saved to %s\" % name)\n",
    "    \n",
    "def print_scores(acc, err, batch_size):\n",
    "    # just an utility printing function\n",
    "    for name, scores in zip((\"accuracy\", \"error\"), (acc, err)):\n",
    "        print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")\n",
    "\n",
    "def confusion_matrix(y_pred, y_true, threshold=0.5):\n",
    "    y_pred, y_true = y_pred.view(-1), y_true.view(-1).int()\n",
    "    y_pred = rounding(y_pred, threshold).int()\n",
    "#     fn = (1-y_pred == y_true).sum()\n",
    "#     ap = (y_pred == y_true).sum()\n",
    "#     an = (y_pred != y_true).sum()\n",
    "#     fp = (y_pred == 1-y_true).sum()\n",
    "#     fn,fp,ap,an = fn.item(),fp.item(),ap.item(),an.item()\n",
    "#     error = (fn + fp) / (fp+fn+ap+an) * 100\n",
    "#     accuracy = (ap+an) / (fp+fn+ap+an) * 100\n",
    "    corrects = y_true == y_pred\n",
    "    accuracy = torch.mean(corrects.type(torch.FloatTensor))\n",
    "    return accuracy, 1-accuracy #accuracy, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    \n",
    "def train(epoch, num_epoch, model, dataloader, criterion, optimizer):\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    for idx, ((img1,img2),label) in enumerate(dataloader):\n",
    "        data_time.update(time.time() - end_time)\n",
    "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model.forward(img1, img2) #forward prop\n",
    "        loss = criterion(output1, output2, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.update(loss.item(), img1.size(0))\n",
    "        batch_time.update(time.time() - end_time)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if idx % PRINT_EVERY == 0:\n",
    "            print(f'Train Epoch [{epoch+1}/{num_epoch}] [{idx}/{len(dataloader)}]\\t'\n",
    "                  f' Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  f' Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  f' Loss {losses.val:.4f} ({losses.avg:.4f}) ')\n",
    "        \n",
    "    return losses.avg\n",
    "        \n",
    "def valid(epoch, num_epoch, model, dataloader, criterion, optimizer):\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = 0\n",
    "    accl = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end_time = time.time()\n",
    "        for idx, ((img1,img2),label) in enumerate(dataloader):\n",
    "            data_time.update(time.time() - end_time)\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "            output1, output2 = model.forward(img1, img2) #forward prop\n",
    "            loss = criterion(output1, output2, label)\n",
    "\n",
    "            predicted_label = F.pairwise_distance(output1, output2)\n",
    "            acc, err = confusion_matrix(predicted_label, label, threshold=0.5)\n",
    "            accuracy += acc\n",
    "            accl.append(acc)\n",
    "            \n",
    "            losses.update(loss.item(), img1.size(0))\n",
    "            batch_time.update(time.time() - end_time)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            if idx % PRINT_EVERY == 0:\n",
    "                print(f'Valid Epoch [{epoch + 1}/{num_epoch}] [{idx}/{len(dataloader)}]\\t'\n",
    "                      f' Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      f' Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                      f' Loss {losses.val:.4f} ({losses.avg:.4f})\\t Accuracy: {accuracy/5:.3f}')\n",
    "                accuracy = 0\n",
    "    print(f\"Valid accuracy one complete epoch: {sum(accl)/len(accl)}\")\n",
    "            \n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8d732cd26846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlen_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlaccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "progress = tqdm(enumerate(validloader, 1))\n",
    "len_valid = len(validloader)\n",
    "laccuracy = []\n",
    "with torch.no_grad():\n",
    "    for idx, ((img1,img2),label) in progress:\n",
    "        img1 = img1.to(device)\n",
    "        img2 = img2.to(device)\n",
    "        label = label.to(device)\n",
    "        out1, out2 = model.forward(img1,img2)\n",
    "        predicted_label = F.pairwise_distance(out1, out2)\n",
    "\n",
    "\n",
    "        acc, err = confusion_matrix(predicted_label, label, threshold=0.5)\n",
    "        progress.set_description(f'Val acc {idx}/{len_valid}: {acc.item():.3f}')\n",
    "        laccuracy.append(acc.item())\n",
    "    \n",
    "print(f\"Avg valid accuracy: {sum(laccuracy)/len(laccuracy)}\")\n",
    "# y_true = np.array(list(itertools.chain(*labels)))\n",
    "# y_pred = np.array(list(itertools.chain(*preds)))\n",
    "# tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_pred).ravel()\n",
    "# total = tn+tp+fp+fn\n",
    "# print(f'Predicted true and actually true: {tp}'\n",
    "#       f'\\nPredicted false and actually false: {tn}'\n",
    "#       f'\\nPredicted true but actually false: {fp}'\n",
    "#       f'\\nPredicted false but actually true: {fn}'\n",
    "#       f'\\nTotal correct predictions: {tp+tn} ({(tp+tn)/total*100:.2f})'\n",
    "#       f'\\nTotal wrong predictions: {fn+fp} ({(fn+fp)/total*100:.2f})'\n",
    "#       f'\\nTotal: ({total})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y,z = next(iter(valid_loader))\n",
    "# o1, o2 = model(x,y)\n",
    "# pred = F.pairwise_distance(o1,o2)\n",
    "\n",
    "# idx = 0\n",
    "# fig, ax = plt.subplots(ncols=2, nrows=1)\n",
    "# ax[0].imshow(x[idx].permute(1,2,0))\n",
    "# ax[1].imshow(y[idx].permute(1,2,0))\n",
    "# print(z[idx])\n",
    "# print(pred[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = metrics.accuracy_score(y_true, y_pred)*100\n",
    "# f1 = metrics.f1_score(y_true, y_pred)*100\n",
    "# prec = metrics.precision_score(y_true, y_pred)*100\n",
    "# print(f'Batch Size: {BATCH_SIZE}\\t Learning Rate: {LEARNING_RATE}\\t NUM EPOCH: {NUM_EPOCH}')\n",
    "# print(f'Accuracy: {acc:.2f}\\t F1: {f1:.2f}\\t Precision: {prec:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for training_logs.csv purpose\n",
    "# log_training_result(NUM_EPOCH, BATCH_SIZE, LEARNING_RATE, acc, prec, f1, tp, tn, fp, fn, model.model.fc, ARCHITECTURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pandas.read_csv(\"training_logs.csv\")\n",
    "# df[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SiameseDensnet().to(device)\n",
    "\n",
    "# fc = nn.Sequential(\n",
    "#     nn.Linear(1024, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(.2),\n",
    "    \n",
    "#     nn.Linear(256, 128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(.2),\n",
    "    \n",
    "#     nn.Linear(128, 64),\n",
    "# )\n",
    "\n",
    "# model.set_classifier(fc)\n",
    "# model.freeze_all_except_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created!\n"
     ]
    }
   ],
   "source": [
    "class SiameseTrainer(nn.Module):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, p, q):\n",
    "        return self.model(p), self.model(q)\n",
    "\n",
    "base = models.resnet101(pretrained=True)\n",
    "\n",
    "for param in base.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# for param in b\n",
    "    \n",
    "in_features = base.fc.in_features\n",
    "base.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(.2),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(.2),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(64, 64)\n",
    ")\n",
    "\n",
    "criterion = ContrastiveLoss(device)\n",
    "optimizer = optim.SGD(base.fc.parameters(), lr=.0035)\n",
    "\n",
    "base.to(device)\n",
    "base = nn.DataParallel(base)\n",
    "model = SiameseTrainer(base)\n",
    "\n",
    "print('model created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(base.module.fc.parameters(), lr=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrain, lvalid = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [1/10] [0/29]\t Time 20.950 (20.950)\t Data 15.619 (15.619)\t Loss 3.4570 (3.4570) \n",
      "Valid Epoch [1/10] [0/13]\t Time 21.398 (21.398)\t Data 18.509 (18.509)\t Loss 1.1113 (1.1113)\t Accuracy: 0.096\n",
      "Valid accuracy one complete epoch: 0.49123984575271606\n",
      "Train Epoch [2/10] [0/29]\t Time 20.942 (20.942)\t Data 17.886 (17.886)\t Loss 2.4643 (2.4643) \n",
      "Valid accuracy one complete epoch: 0.4890440106391907\n",
      "Train Epoch [4/10] [0/29]\t Time 21.474 (21.474)\t Data 18.414 (18.414)\t Loss 1.5173 (1.5173) \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    trainloss = train(epoch, NUM_EPOCH, model, trainloader, criterion, optimizer)\n",
    "    validloss = valid(epoch, NUM_EPOCH, model, validloader, criterion, optimizer)\n",
    "    ltrain.append(trainloss)\n",
    "    lvalid.append(validloss)\n",
    "\n",
    "plt.plot(history['train'], label='train_loss')\n",
    "plt.plot(history['valid'], label='valid_loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
